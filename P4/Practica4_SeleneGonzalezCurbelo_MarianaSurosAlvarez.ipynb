{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if an image has alpha channel (RGBA) or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen tiene un canal alfa (RGBA)\n",
      "La imagen tiene un canal alfa (RGBA)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "items = [\n",
    "    cv2.imread('./Images/Lips/vampire1.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/Beards/beard1.png', cv2.IMREAD_UNCHANGED),\n",
    "]\n",
    "\n",
    "for item in items:\n",
    "    num_chan = item.shape[2]\n",
    "\n",
    "    if num_chan == 4:\n",
    "        print(f\"La imagen tiene un canal alfa (RGBA)\")\n",
    "    else:\n",
    "        print(f\"La imagen tiene un canal NO alfa (NO RGBA)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------- Multiple face detection -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hats code (mfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "\n",
    "hats = [\n",
    "    cv2.imread('./Images/No_trim/hat2.png', cv2.IMREAD_UNCHANGED), \n",
    "    cv2.imread('./Images/No_trim/hat3.png', cv2.IMREAD_UNCHANGED), \n",
    "    cv2.imread('./Images/No_trim/hat4.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/hat5.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/hat6.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/flowercrown1.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/chef.png', cv2.IMREAD_UNCHANGED),\n",
    "]\n",
    "\n",
    "current_hat = 0\n",
    " \n",
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "p = \"./shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    " \n",
    "while True:\n",
    "    # load the input image and convert it to grayscale\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "        \n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        top_head_x = int(np.mean(shape[0:27, 0]))\n",
    "        top_head_y = int(np.mean(shape[0:27, 1]))\n",
    "\n",
    "        hat_width = int(1.5 * rect.width())\n",
    "        hat_height = hat_width * hats[current_hat].shape[0] // hats[current_hat].shape[1]\n",
    "\n",
    "        x = top_head_x - hat_width // 2\n",
    "        y = top_head_y - hat_height\n",
    "\n",
    "        hat_resized = cv2.resize(hats[current_hat], (hat_width, hat_height))\n",
    "\n",
    "        for i in range(hat_height):\n",
    "            for j in range(hat_width):\n",
    "                if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and hat_resized[i, j, 3] != 0:\n",
    "                    image_rgba[y + i, x + j] = hat_resized[i, j]\n",
    "    \n",
    "    # show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Output\", image_rgba)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k >= ord('1') and k <= ord('8'):\n",
    "        current_hat = k - ord('1')\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beards & moustaches code (mfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "\n",
    "beards = [\n",
    "    cv2.imread('./Images/No_trim/beard1.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/beard3.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/beard4.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/beard2.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/beard5.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/beard6.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/beard7.png', cv2.IMREAD_UNCHANGED),\n",
    "]\n",
    "\n",
    "current_beard = 0\n",
    " \n",
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "p = \"./shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    " \n",
    "while True:\n",
    "    # load the input image and convert it to grayscale\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "        \n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        top_head_x = int(np.mean(shape[0:27, 0]))\n",
    "        top_head_y = int(np.mean(shape[0:27, 1]))\n",
    "\n",
    "        beard_width = int(1.5 * rect.width())\n",
    "        beard_height = beard_width * beards[current_beard].shape[0] // beards[current_beard].shape[1]\n",
    "\n",
    "        x = top_head_x - beard_width // 2\n",
    "        y = int(0.98 * shape[30][1])\n",
    "\n",
    "        beard_resized = cv2.resize(beards[current_beard], (beard_width, beard_height))\n",
    "\n",
    "        for i in range(beard_height):\n",
    "            for j in range(beard_width):\n",
    "                if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and beard_resized[i, j, 3] != 0:\n",
    "                    image_rgba[y + i, x + j] = beard_resized[i, j]\n",
    "    \n",
    "    # show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Output\", image_rgba)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k >= ord('1') and k <= ord('7'):\n",
    "        current_beard = k - ord('1')\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lips code (mfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "\n",
    "lips_items = [\n",
    "    cv2.imread('./Images/No_trim/anime1.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/anime2.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/black1.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/sexy2.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/vampire1.png', cv2.IMREAD_UNCHANGED),\n",
    "]\n",
    "\n",
    "current_item = 0\n",
    "\n",
    "# Initialize dlib's face detector (HOG-based) and create the facial landmark predictor\n",
    "p = \"./shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while True:\n",
    "    # Load the input image and convert it to grayscale\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        # Get the coordinates of the lips\n",
    "        lips = shape[48:68]\n",
    "\n",
    "        # Calculate the center of the lips\n",
    "        lips_center = (int((lips[0][0] + lips[6][0]) / 2), int((lips[0][1] + lips[6][1]) / 2))\n",
    "\n",
    "        # Calculate the width and height for the overlay image\n",
    "        overlay_width = int((lips[6][0] - lips[0][0]))\n",
    "        overlay_height = int(0.8 * overlay_width)\n",
    "\n",
    "        # Resize the overlay image to fit the lips\n",
    "        overlay_image_resized = cv2.resize(lips_items[current_item], (overlay_width, overlay_height)) #cv2.resize(beard, (overlay_width, overlay_height))\n",
    "\n",
    "        # Calculate the position to overlay the image on the lips\n",
    "        x_pos = lips_center[0] - overlay_width // 2\n",
    "        y_pos = lips_center[1] - overlay_height // 2\n",
    "\n",
    "        # Ensure that the overlay image is within the bounds of the original image\n",
    "        if x_pos >= 0 and y_pos >= 0 and x_pos + overlay_width <= image.shape[1] and y_pos + overlay_height <= image.shape[0]:\n",
    "            # Create a mask based on the alpha channel of the overlay image\n",
    "            mask = overlay_image_resized[:, :, 3] / 255.0\n",
    "            mask = cv2.merge([mask, mask, mask])\n",
    "\n",
    "            # Mix the two images using the mask\n",
    "            overlay_region = overlay_image_resized[:, :, 0:3]\n",
    "            image[y_pos:y_pos + overlay_height, x_pos:x_pos + overlay_width] = (1 - mask) * image[y_pos:y_pos + overlay_height, x_pos:x_pos + overlay_width] + mask * overlay_region\n",
    "\n",
    "    # Show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Output\", image)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k >= ord('1') and k <= ord('3'):\n",
    "        current_item = k - ord('1')\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glasses code (mfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "\n",
    "# Initialize dlib's face detector (HOG-based) and create the facial landmark predictor\n",
    "p = \"./shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "glasses_items = [\n",
    "    cv2.imread(\"./Images/No_trim/glasses1.png\", cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/glasses2.png', cv2.IMREAD_UNCHANGED),\n",
    "    cv2.imread('./Images/No_trim/glasses3.png', cv2.IMREAD_UNCHANGED),\n",
    "]\n",
    "\n",
    "current_item = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Load the input image and convert it to grayscale\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        # Detect eyes\n",
    "        left_eye = shape[42:48]\n",
    "        right_eye = shape[36:42]\n",
    "\n",
    "        # Calculate the center of both eyes\n",
    "        left_eye_center = np.mean(left_eye, axis=0).astype(int)\n",
    "        right_eye_center = np.mean(right_eye, axis=0).astype(int)\n",
    "\n",
    "        # Calculate the center between the eyes\n",
    "        eyes_center = ((left_eye_center[0] + right_eye_center[0]) // 2, (left_eye_center[1] + right_eye_center[1]) // 2)\n",
    "\n",
    "        # Calculate the scale factor for the glasses\n",
    "        distance = abs(left_eye_center[0] - right_eye_center[0])\n",
    "        scale_factor = 2.0 * distance / glasses_items[current_item].shape[1]  # Adjust scale as needed\n",
    "\n",
    "        # Resize the glasses image\n",
    "        new_glasses = cv2.resize(glasses_items[current_item], (0, 0), fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "        # Calculate the position to place the glasses centered between the eyes\n",
    "        x_offset = eyes_center[0] - new_glasses.shape[1] // 2\n",
    "        y_offset = eyes_center[1] - new_glasses.shape[0] // 2\n",
    "\n",
    "        # Superpose the glasses on the face\n",
    "        for c in range(0, 3):\n",
    "            image[y_offset:y_offset + new_glasses.shape[0], x_offset:x_offset + new_glasses.shape[1], c] = (\n",
    "                image[y_offset:y_offset + new_glasses.shape[0], x_offset:x_offset + new_glasses.shape[1], c] * (1 - new_glasses[:, :, 3] / 255.0) +\n",
    "                new_glasses[:, :, c] * (new_glasses[:, :, 3] / 255.0)\n",
    "            )\n",
    "\n",
    "    # show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Output\", image)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k >= ord('1') and k <= ord('3'):\n",
    "        current_item = k - ord('1')\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------- Landmark code face detectection -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hats code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "import FaceDetectors\n",
    "import os\n",
    "\n",
    "normalizatorHS = faceutils.Normalization()\n",
    "FDet = FaceDetectors.FaceDetector()\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "hats_file = './Images/Hats/'\n",
    "hats = os.listdir(hats_file)\n",
    "hats_index = 0\n",
    "\n",
    "frames_no_face = 0\n",
    "umbral_frames_no_face  = 5\n",
    "next_index = True\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check for other cameras\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print('Camera error')\n",
    "            exit(0)\n",
    "        else:\n",
    "            print('Camera 0')\n",
    "    else:\n",
    "        print('Camera 1')\n",
    "else:\n",
    "    print('Camera 0')\n",
    "\n",
    "imodoF = 2\n",
    "imodoE = 1\n",
    "\n",
    "debug = 0\n",
    "\n",
    "#Set camera resolution\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    " \n",
    "while True:\n",
    "    # Get frame\n",
    "    t = time.time()\n",
    "    ret, image = cap.read()\n",
    "    # For HS normalization\n",
    "    B, G, R = cv2.split(image)\n",
    "    # Load the input image and convert it to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "    # Detect faces in the grayscale image\n",
    "    values = FDet.SingleFaceEyesDetection(image, FDet.FaceDetectors[imodoF], FDet.EyeDetectors[imodoE])\n",
    "    if values is not None:\n",
    "        face, eyes, shape = values\n",
    "\n",
    "        if len(shape) == 0:\n",
    "            frames_no_face  += 1\n",
    "        else:\n",
    "            frames_no_face  = 0\n",
    "            next_index = True\n",
    "\n",
    "        if frames_no_face  >= umbral_frames_no_face  and next_index:\n",
    "            hats_index = (hats_index + 1) % len(hats)\n",
    "            frames_no_face  = 0\n",
    "            next_index = False\n",
    "        \n",
    "        if len(shape) > 0:\n",
    "            top_head_x = shape[0][0]\n",
    "            top_head_y = shape[19][1]\n",
    "\n",
    "            hat = cv2.imread(os.path.join(hats_file, hats[hats_index]), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            hat_width = shape[16][0] - shape[0][0]\n",
    "            hat_height = hat_width * hat.shape[0] // hat.shape[1] \n",
    "                      \n",
    "            hat_resized = cv2.resize(hat, (hat_width, hat_height))\n",
    "\n",
    "            x = top_head_x \n",
    "            y = top_head_y - hat_height - 45\n",
    "\n",
    "            for i in range(hat_height):\n",
    "                for j in range(hat_width):\n",
    "                    if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and hat_resized[i, j, 3] != 0:\n",
    "                        image_rgba[y + i, x + j] = hat_resized[i, j]\n",
    "\n",
    "    if debug:\n",
    "        print(\"Processing time : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "    # Show resulting image\n",
    "    cv2.putText(image_rgba, FDet.FaceDetectors[imodoF], (10, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    if imodoF == 1 or imodoF == 2:\n",
    "        cv2.putText(image_rgba, FDet.EyeDetectors[imodoE], (50, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Cam', image_rgba)\n",
    "\n",
    "    tec = cv2.waitKey(40)\n",
    "    if tec & tec == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beards code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "import FaceDetectors\n",
    "import os\n",
    "\n",
    "normalizatorHS = faceutils.Normalization()\n",
    "\n",
    "FDet = FaceDetectors.FaceDetector()\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "beards_file = './Images/Beards/'\n",
    "beards = os.listdir(beards_file)\n",
    "beards_index = 0\n",
    "\n",
    "frames_no_face = 0\n",
    "umbral_frames_no_face  = 5\n",
    "next_index = True\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check for other cameras\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print('Camera error')\n",
    "            exit(0)\n",
    "        else:\n",
    "            print('Camera 0')\n",
    "    else:\n",
    "        print('Camera 1')\n",
    "else:\n",
    "    print('Camera 0')\n",
    "\n",
    "imodoF = 2\n",
    "imodoE = 1\n",
    "\n",
    "debug = 0\n",
    "\n",
    "#Set camera resolution\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    " \n",
    "while True:\n",
    "    # Get frame\n",
    "    t = time.time()\n",
    "    ret, image = cap.read()\n",
    "    # For HS normalization\n",
    "    B, G, R = cv2.split(image)\n",
    "    # Load the input image and convert it to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "    # Detect faces in the grayscale image\n",
    "    values = FDet.SingleFaceEyesDetection(image, FDet.FaceDetectors[imodoF], FDet.EyeDetectors[imodoE])\n",
    "    if values is not None:\n",
    "        face, eyes, shape = values\n",
    "\n",
    "        if len(shape) == 0:\n",
    "            frames_no_face  += 1\n",
    "        else:\n",
    "            frames_no_face  = 0\n",
    "            next_index = True\n",
    "\n",
    "        if frames_no_face  >= umbral_frames_no_face  and next_index:\n",
    "            beards_index = (beards_index + 1) % len(beards)\n",
    "            frames_no_face  = 0\n",
    "            next_index = False\n",
    "        \n",
    "        if len(shape) > 0:\n",
    "            top_head_x = shape[2][0] - 3\n",
    "            top_head_y = shape[30][1]\n",
    "\n",
    "        # cv2.circle(image_rgba, (shape[33][0], shape[33][1]), 2, (0, 255, 0), -1)\n",
    "\n",
    "        # cv2.circle(image_rgba, (shape[2][0], shape[2][1]), 2, (0, 255, 0), -1)\n",
    "        # cv2.circle(image_rgba, (shape[14][0], shape[14][1]), 2, (0, 0, 255), -1)\n",
    "\n",
    "            beard = cv2.imread(os.path.join(beards_file, beards[beards_index]), cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "            beard_width = (shape[15][0]) - (shape[1][0])\n",
    "            beard_height = shape[8][1] - shape[33][1] + 50\n",
    "\n",
    "            beard_resized = cv2.resize(beard, (beard_width, beard_height))\n",
    "\n",
    "            x = top_head_x \n",
    "            y = top_head_y\n",
    "\n",
    "        for i in range(beard_height):\n",
    "            for j in range(beard_width):\n",
    "                if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and beard_resized[i, j, 3] != 0:\n",
    "                    image_rgba[y + i, x + j] = beard_resized[i, j]\n",
    "        \n",
    "    if debug:\n",
    "        print(\"Processing time : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "    # Show resulting image\n",
    "    cv2.putText(image_rgba, FDet.FaceDetectors[imodoF], (10, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    if imodoF == 1 or imodoF == 2:\n",
    "        cv2.putText(image_rgba, FDet.EyeDetectors[imodoE], (50, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Cam', image_rgba)\n",
    "\n",
    "    tec = cv2.waitKey(40)\n",
    "    if tec & tec == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moustaches code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "import FaceDetectors\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "normalizatorHS = faceutils.Normalization()\n",
    "\n",
    "FDet = FaceDetectors.FaceDetector()\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "moustaches_file = './Images/Moustaches/'\n",
    "moustaches = os.listdir(moustaches_file)\n",
    "moustaches_index = 0\n",
    "\n",
    "frames_no_face = 0\n",
    "umbral_frames_no_face  = 5\n",
    "next_index = True\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check for other cameras\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print('Camera error')\n",
    "            exit(0)\n",
    "        else:\n",
    "            print('Camera 0')\n",
    "    else:\n",
    "        print('Camera 1')\n",
    "else:\n",
    "    print('Camera 0')\n",
    "\n",
    "imodoF = 2\n",
    "imodoE = 1\n",
    "\n",
    "debug = 0\n",
    "\n",
    "#Set camera resolution\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    " \n",
    "while True:\n",
    "    # Get frame\n",
    "    t = time.time()\n",
    "    ret, image = cap.read()\n",
    "    # For HS normalization\n",
    "    B, G, R = cv2.split(image)\n",
    "    # Load the input image and convert it to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    # Detect faces in the grayscale image\n",
    "    values = FDet.SingleFaceEyesDetection(image, FDet.FaceDetectors[imodoF], FDet.EyeDetectors[imodoE])\n",
    "    if values is not None:\n",
    "        face, eyes, shape = values\n",
    "\n",
    "        if len(shape) == 0:\n",
    "            frames_no_face  += 1\n",
    "        else:\n",
    "            frames_no_face  = 0\n",
    "            next_index = True\n",
    "\n",
    "        if frames_no_face  >= umbral_frames_no_face  and next_index:\n",
    "            moustaches_index = (moustaches_index + 1) % len(moustaches)\n",
    "            frames_no_face  = 0\n",
    "            next_index = False\n",
    "        \n",
    "        if len(shape) > 0:\n",
    "            top_head_x = shape[48][0]\n",
    "            top_head_y = shape[33][1]\n",
    "\n",
    "            beard = cv2.imread(os.path.join(moustaches_file, moustaches[moustaches_index]), cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "            nose_x, nose_y = shape[33]\n",
    "            upper_lip_x = int((shape[48][0] + shape[54][0]) / 2)\n",
    "            upper_lip_y = np.mean(shape[48:54, 1])\n",
    "\n",
    "            y_offset = int((nose_y - upper_lip_y) * 0.8)\n",
    "            beard_width = int(shape[54][0] - shape[48][0]) + 50\n",
    "            beard_height = int(shape[51][1] - shape[33][1]) + 5\n",
    "\n",
    "            beard_resized = cv2.resize(beard, (beard_width, beard_height))\n",
    "\n",
    "            x = int(upper_lip_x - beard_width / 2)\n",
    "            y = int(upper_lip_y + y_offset)\n",
    "\n",
    "            for i in range(beard_height):\n",
    "                for j in range(beard_width):\n",
    "                    if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and beard_resized[i, j, 3] != 0:\n",
    "                        image_rgba[y + i, x + j] = beard_resized[i, j]\n",
    "        \n",
    "    if debug:\n",
    "        print(\"Processing time : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "    # Show resulting image\n",
    "    cv2.putText(image_rgba, FDet.FaceDetectors[imodoF], (10, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    if imodoF == 1 or imodoF == 2:\n",
    "        cv2.putText(image_rgba, FDet.EyeDetectors[imodoE], (50, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Cam', image_rgba)\n",
    "\n",
    "    tec = cv2.waitKey(40)\n",
    "    if tec & tec == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lips code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "import FaceDetectors\n",
    "import os\n",
    "\n",
    "normalizatorHS = faceutils.Normalization()\n",
    "FDet = FaceDetectors.FaceDetector()\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "lips_file = './Images/Lips/'\n",
    "lips = os.listdir(lips_file)\n",
    "lips_index = 0\n",
    "\n",
    "frames_no_face = 0\n",
    "umbral_frames_no_face  = 5\n",
    "next_index = True\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check for other cameras\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print('Camera error')\n",
    "            exit(0)\n",
    "        else:\n",
    "            print('Camera 0')\n",
    "    else:\n",
    "        print('Camera 1')\n",
    "else:\n",
    "    print('Camera 0')\n",
    "\n",
    "imodoF = 2\n",
    "imodoE = 1\n",
    "\n",
    "debug = 0\n",
    "\n",
    "#Set camera resolution\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "\n",
    "while True:\n",
    "    # Get frame\n",
    "    t = time.time()\n",
    "    ret, image = cap.read()\n",
    "    # For HS normalization\n",
    "    B, G, R = cv2.split(image)\n",
    "    # Load the input image and convert it to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    # Detect faces in the grayscale image\n",
    "    values = FDet.SingleFaceEyesDetection(image, FDet.FaceDetectors[imodoF], FDet.EyeDetectors[imodoE])\n",
    "    if values is not None:\n",
    "        face, eyes, shape = values\n",
    "\n",
    "        if len(shape) == 0:\n",
    "            frames_no_face  += 1\n",
    "        else:\n",
    "            frames_no_face  = 0\n",
    "            next_index = True\n",
    "\n",
    "        if frames_no_face  >= umbral_frames_no_face  and next_index:\n",
    "            lips_index = (lips_index + 1) % len(lips)\n",
    "            frames_no_face  = 0\n",
    "            next_index = False\n",
    "\n",
    "        if len(shape) > 0:\n",
    "            top_head_x = shape[48][0]\n",
    "            top_head_y = shape[50][1]\n",
    "\n",
    "            lip = cv2.imread(os.path.join(lips_file, lips[lips_index]), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            lip_width = shape[54][0] - shape[48][0]\n",
    "            lip_height = shape[58][1] - shape[50][1]\n",
    "\n",
    "            lip_resized = cv2.resize(lip, (lip_width, lip_height))\n",
    "\n",
    "        # print(\"shape[50][0] - shape[58][0]\")\n",
    "        # print(\"boca_width\")\n",
    "        # print(boca_width)\n",
    "        # print(\"boca_height\")\n",
    "        # print(boca_height)\n",
    "\n",
    "        # cv2.circle(image_rgba, (shape[54][0], shape[54][1]), 2, (255, 0, 0), -1)\n",
    "        # cv2.circle(image_rgba, (shape[48][0], shape[48][1]), 2, (255, 0, 0), -1)\n",
    "        # cv2.circle(image_rgba, (shape[57][0], shape[57][1]), 2, (0, 255, 0), -1)\n",
    "        # cv2.circle(image_rgba, (shape[50][0], shape[50][1]), 2, (0, 255, 0), -1)\n",
    "\n",
    "        # boca_resized = cv2.resize(boca, (boca_width, boca_height))\n",
    "\n",
    "            x = top_head_x \n",
    "            y = top_head_y\n",
    "        \n",
    "            for i in range(lip_height):\n",
    "                for j in range(lip_width):\n",
    "                    if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and lip_resized[i, j, 3] != 0:\n",
    "                        image_rgba[y + i, x + j] = lip_resized[i, j]\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Processing time : {:.3f}\".format(time.time() - t))\n",
    "        \n",
    "    # Show resulting image\n",
    "    cv2.putText(image_rgba, FDet.FaceDetectors[imodoF], (10, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    if imodoF == 1 or imodoF == 2:\n",
    "        cv2.putText(image_rgba, FDet.EyeDetectors[imodoE], (50, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Cam', image_rgba)\n",
    "\n",
    "    tec = cv2.waitKey(40)\n",
    "    if tec & tec == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glasses code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "import FaceDetectors\n",
    "import os\n",
    "\n",
    "normalizatorHS = faceutils.Normalization()\n",
    "\n",
    "FDet = FaceDetectors.FaceDetector()\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "glasses_file = './Images/Glasses/'\n",
    "glasses = os.listdir(glasses_file)\n",
    "glasses_index = 0\n",
    "\n",
    "frames_no_face = 0\n",
    "umbral_frames_no_face  = 5\n",
    "next_index = True\n",
    "\n",
    "# Webcam connection\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Check for other cameras\n",
    "if not cap.isOpened():\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    if not cap.isOpened():\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print('Camera error')\n",
    "            exit(0)\n",
    "        else:\n",
    "            print('Camera 0')\n",
    "    else:\n",
    "        print('Camera 1')\n",
    "else:\n",
    "    print('Camera 0')\n",
    "\n",
    "imodoF = 2\n",
    "imodoE = 1\n",
    "\n",
    "debug = 0\n",
    "\n",
    "#Set camera resolution\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "\n",
    "while True:\n",
    "    # Get frame\n",
    "    t = time.time()\n",
    "    ret, image = cap.read()\n",
    "    # For HS normalization\n",
    "    B, G, R = cv2.split(image)\n",
    "    # Load the input image and convert it to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "    # Detect faces in the grayscale image\n",
    "    values = FDet.SingleFaceEyesDetection(image, FDet.FaceDetectors[imodoF], FDet.EyeDetectors[imodoE])\n",
    "    if values is not None:\n",
    "        face, eyes, shape = values\n",
    "\n",
    "        if len(shape) == 0:\n",
    "            frames_no_face  += 1\n",
    "        else:\n",
    "            frames_no_face  = 0\n",
    "            next_index = True\n",
    "\n",
    "        if frames_no_face  >= umbral_frames_no_face  and next_index:\n",
    "            glasses_index = (glasses_index + 1) % len(glasses)\n",
    "            frames_no_face  = 0\n",
    "            next_index = False\n",
    "        \n",
    "        if len(shape) > 0:\n",
    "            top_head_x = shape[0][0]\n",
    "            top_head_y = shape[37][1]\n",
    "\n",
    "            glass = cv2.imread(os.path.join(glasses_file, glasses[glasses_index]), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            glass_width = shape[16][0] - shape[0][0]\n",
    "            glass_height = glass_width * glass.shape[0] // glass.shape[1] \n",
    "                        \n",
    "            glass_resized = cv2.resize(glass, (glass_width, glass_height))\n",
    "\n",
    "            x = top_head_x \n",
    "            y = top_head_y - (glass_height // 2) \n",
    "            \n",
    "            for i in range(glass_height):\n",
    "                for j in range(glass_width):\n",
    "                    if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and glass_resized[i, j, 3] != 0:\n",
    "                        image_rgba[y + i, x + j] = glass_resized[i, j]\n",
    "\n",
    "    if debug:\n",
    "        print(\"Processing time : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "    # Show resulting image\n",
    "    cv2.putText(image_rgba, FDet.FaceDetectors[imodoF], (10, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    if imodoF == 1 or imodoF == 2:\n",
    "        cv2.putText(image_rgba, FDet.EyeDetectors[imodoE], (50, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Cam', image_rgba)\n",
    "\n",
    "    tec = cv2.waitKey(40)\n",
    "    if tec & tec == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UI selector: beards, moustaches, lips, hats and glasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera 0 iniciada\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import tkinter\n",
    "import cv2\n",
    "import time\n",
    "import FaceNormalizationUtils as faceutils\n",
    "import FaceDetectors\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Función para inicializar la cámara\n",
    "def inicializar_camara():\n",
    "    for i in range(3):\n",
    "        cap = cv2.VideoCapture(i)\n",
    "        if cap.isOpened():\n",
    "            print(f'Camera {i} iniciada')\n",
    "            return cap\n",
    "    print('No se pudo iniciar la cámara')\n",
    "    exit(1)\n",
    "\n",
    "cap = inicializar_camara()\n",
    "\n",
    "cap.set(3, 640)  # Establecer resolución\n",
    "cap.set(4, 480)\n",
    "\n",
    "FDet = FaceDetectors.FaceDetector()\n",
    "\n",
    "def cargar_objetos(indice):\n",
    "    global objects\n",
    "    objects = ['./Images/Hats/', './Images/Glasses/', './Images/Lips/', './Images/Moustaches/', './Images/Beards/']\n",
    "    return os.listdir(objects[indice])\n",
    "\n",
    "def obtener_posicion_objeto(indice, shape, object, face):\n",
    "    \n",
    "    if indice == 0:\n",
    "        top_object_x = shape[0][0]\n",
    "        top_object_y = shape[19][1]\n",
    "        object_width = shape[16][0] - shape[0][0]\n",
    "        object_height = object_width * object.shape[0] // object.shape[1] \n",
    "        x = top_object_x \n",
    "        y = top_object_y - object_height - 45\n",
    "    elif indice == 1:\n",
    "        top_object_x = shape[0][0]\n",
    "        top_object_y = shape[37][1]\n",
    "\n",
    "        object_width = shape[16][0] - shape[0][0]\n",
    "        object_height = object_width * object.shape[0] // object.shape[1] \n",
    "\n",
    "        x = int(top_object_x)\n",
    "        y = int(top_object_y - (object_height // 2))\n",
    "    elif indice == 2:\n",
    "        top_object_x = shape[48][0]\n",
    "        top_object_y = shape[50][1]\n",
    "\n",
    "        object_width = shape[54][0] - shape[48][0]\n",
    "        object_height = shape[58][1] - shape[50][1]\n",
    "\n",
    "        x = int(top_object_x)\n",
    "        y = int(top_object_y)\n",
    "    elif indice == 3:\n",
    "        top_object_x = shape[48][0]\n",
    "        top_object_y = shape[33][1]\n",
    "\n",
    "        nose_x, nose_y = shape[33]\n",
    "        upper_lip_x = int((shape[48][0] + shape[54][0]) / 2)\n",
    "        upper_lip_y = np.mean(shape[48:54, 1])\n",
    "\n",
    "        y_offset = int((nose_y - upper_lip_y) * 0.8)\n",
    "        object_width = int(shape[54][0] - shape[48][0]) + 50\n",
    "        object_height = int(shape[51][1] - shape[33][1]) + 5\n",
    "\n",
    "        x = int(upper_lip_x - object_width / 2)\n",
    "        y = int(upper_lip_y + y_offset)\n",
    "\n",
    "    elif indice == 4:\n",
    "        top_object_x = shape[2][0] - 3\n",
    "        top_object_y = shape[30][1]\n",
    "\n",
    "        object_width = (shape[15][0]) - (shape[1][0])\n",
    "        object_height = shape[8][1] - shape[33][1] + 50\n",
    "\n",
    "        x = int(top_object_x)\n",
    "        y = int(top_object_y)\n",
    "    \n",
    "    return x, y, object_width, object_height\n",
    "\n",
    "def iniciar_gui():\n",
    "    global modos\n",
    "    global indice_seleccionado\n",
    "    \n",
    "    try:\n",
    "        ventana = tkinter.Tk()\n",
    "        ventana.title('Modos')\n",
    "            \n",
    "        for indice, modo in enumerate(modos):\n",
    "            boton = tkinter.Button(ventana, text=modo, command=lambda i=indice: seleccionar_modo_gui(i))\n",
    "            boton.pack(pady=5)\n",
    "\n",
    "        ventana.mainloop()\n",
    "    except Exception as e:\n",
    "        print(\"Error iniciar_gui:\", e)\n",
    "\n",
    "def calcular_angulo(p1, p2):\n",
    "    \"\"\"Calculates the angle between two points.\"\"\"\n",
    "    angle = np.arctan2(p2[1] - p1[1], p2[0] - p1[0])\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def seleccionar_modo_gui(indice):\n",
    "    global object_file\n",
    "    global object_index\n",
    "    global objects\n",
    "    global FDet\n",
    "\n",
    "    frames_no_face = 0\n",
    "    umbral_frames_no  = 5\n",
    "    next_index = True\n",
    "\n",
    "    imodoF = 2\n",
    "    imodoE = 1\n",
    "\n",
    "    debug = 0\n",
    "\n",
    "    try:\n",
    "        if indice is not None and indice < len(modos):\n",
    "            object_file = cargar_objetos(indice)\n",
    "            object_index = 0\n",
    "\n",
    "            while True:\n",
    "                t = time.time()\n",
    "                ret, image = cap.read()\n",
    "                B, G, R = cv2.split(image)\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                image_rgba = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "                values = FDet.SingleFaceEyesDetection(image, FDet.FaceDetectors[imodoF], FDet.EyeDetectors[imodoE])\n",
    "                if values is not None:\n",
    "                    face, eyes, shape = values\n",
    "\n",
    "                    if len(shape) == 0:\n",
    "                        frames_no_face  += 1\n",
    "                    else:\n",
    "                        frames_no_face  = 0\n",
    "                        next_index = True\n",
    "\n",
    "                    if frames_no_face  >= umbral_frames_no  and next_index:\n",
    "                        object_index = (object_index + 1) % len(object_file)\n",
    "                        frames_no_face  = 0\n",
    "                        next_index = False\n",
    "                    \n",
    "                    if len(shape) > 0:\n",
    "                        object = cv2.imread(os.path.join(objects[indice], object_file[object_index]), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "                        x, y, object_width, object_height = obtener_posicion_objeto(indice, shape, object, face)\n",
    "\n",
    "                        object_resized = cv2.resize(object, (object_width, object_height))\n",
    "\n",
    "                        for i in range(object_height):\n",
    "                            for j in range(object_width):\n",
    "                                if 0 <= y + i < image.shape[0] and 0 <= x + j < image.shape[1] and object_resized[i, j, 3] != 0:\n",
    "                                    image_rgba[y + i, x + j] = object_resized[i, j]\n",
    "\n",
    "                if debug:\n",
    "                    print(\"Processing time : {:.3f}\".format(time.time() - t))\n",
    "\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(image_rgba, FDet.FaceDetectors[imodoF], (10, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                if imodoF == 1 or imodoF == 2:\n",
    "                    cv2.putText(image_rgba, FDet.EyeDetectors[imodoE], (50, 20), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                cv2.imshow('Cam', image_rgba)\n",
    "\n",
    "                tec = cv2.waitKey(40)\n",
    "                if tec & tec == 27:\n",
    "                    break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error seleccionar_modo_gui:\", e)\n",
    "\n",
    "modos = ['Sombrero', 'Gafa', 'Boca', 'Bigote', 'Barba']\n",
    "indice_seleccionado = None\n",
    "\n",
    "object_file = None\n",
    "object_index = 0\n",
    "imodoF = 2\n",
    "imodoE = 1\n",
    "\n",
    "imagen_anterior = None\n",
    "\n",
    "gui_thread = Thread(target=iniciar_gui)\n",
    "gui_thread.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
