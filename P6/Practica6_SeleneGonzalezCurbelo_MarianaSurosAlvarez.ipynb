{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Mele\\anaconda3\\envs\\conda_env_fixed_opencv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "from deepface import DeepFace\n",
    "import threading\n",
    "import time\n",
    "import queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools & tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating samples folder (celebrities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Datasets/famosos'\n",
    "\n",
    "for directory in os.listdir(data_dir):\n",
    "    first_file = os.listdir(os.path.join(data_dir, directory))[0]\n",
    "    shutil.copyfile(os.path.join(data_dir, directory, first_file), os.path.join(\"Samples\", f\"{directory}.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookalike test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = DeepFace.verify(\"person1.jpg\", f\"Samples/Angelina Jolie.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verified': False,\n",
       " 'distance': 0.7698307337090413,\n",
       " 'threshold': 0.4,\n",
       " 'model': 'VGG-Face',\n",
       " 'detector_backend': 'opencv',\n",
       " 'similarity_metric': 'cosine',\n",
       " 'facial_areas': {'img1': {'x': 208, 'y': 37, 'w': 120, 'h': 120},\n",
       "  'img2': {'x': 74, 'y': 115, 'w': 287, 'h': 287}},\n",
       " 'time': 0.54}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age, render & race test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'age': 29, 'region': {'x': 208, 'y': 37, 'w': 120, 'h': 120}, 'gender': {'Woman': 4.4589015146812017e-05, 'Man': 99.99995231628418}, 'dominant_gender': 'Man', 'race': {'asian': 0.32646742183715105, 'indian': 7.5354211032390594, 'black': 0.32972635235637426, 'white': 32.79293179512024, 'middle eastern': 32.33891725540161, 'latino hispanic': 26.676541566848755}, 'dominant_race': 'white', 'emotion': {'angry': 3.388790208301382e-08, 'disgust': 5.378273185664511e-13, 'fear': 9.986144302869349e-06, 'happy': 96.66207989002227, 'sad': 2.6955637382574697e-06, 'surprise': 0.008525826995080203, 'neutral': 3.329385841415625}, 'dominant_emotion': 'happy'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "emotionImg = cv2.imread('./person1.jpg')\n",
    "obj = DeepFace.analyze(emotionImg, enforce_detection=False, actions=['age', 'gender', 'race', 'emotion'])\n",
    "\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookalike search with celebrities (images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No exact match found! Closest match is Hugh Jackman\n"
     ]
    }
   ],
   "source": [
    "smallest_distance = None\n",
    "\n",
    "for file in os.listdir(\"Samples\"):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        # result = DeepFace.verify(\"./Images/person1.jpg\", f\"Samples/{file}\")\n",
    "        # result = DeepFace.verify(\"./Images/person2.jpg\", f\"Samples/{file}\")\n",
    "        result = DeepFace.verify(\"./Images/match.jpg\", f\"Samples/{file}\")\n",
    "        if result['verified']:\n",
    "            print(\"This person looks exactly like\", file.split(\".\")[0])\n",
    "            break\n",
    "        if smallest_distance is None: # First instance\n",
    "            smallest_distance = (file.split(\".\")[0], result['distance'])\n",
    "        else:\n",
    "            smallest_distance = (file.split(\".\")[0], result['distance']) if result['distance'] < smallest_distance[1] else smallest_distance\n",
    "else:\n",
    "    print(f\"No exact match found! Closest match is {smallest_distance[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookalike search with celebrities (video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  2.07it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.48it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.78it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.69it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.68it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.77it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.74it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.71it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.57it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.60it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.91it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.70it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.68it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.63it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.80it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.71it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.79it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La persona más parecida es Sandra Bullock con una similitud total de 1.316648349942769\n"
     ]
    }
   ],
   "source": [
    "# Ruta al directorio que contiene las carpetas de categorías (personas)\n",
    "carpeta_referencia = \"./Samples\"\n",
    "\n",
    "# Obtener la lista de categorías (nombres de personas)\n",
    "archivos_referencia = os.listdir(carpeta_referencia)\n",
    "\n",
    "# Inicializar variables para el resultado final\n",
    "persona_mas_parecida = None\n",
    "distancia_minima = float('inf')\n",
    "\n",
    "# Inicializar la captura de la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Capturar el fotograma de la cámara\n",
    "ret, frame = cap.read()\n",
    "frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "# Guardar la imagen temporal\n",
    "cv2.imwrite(\"imagen_temporal.jpg\", frame)\n",
    "imagen_a_comparar = \"imagen_temporal.jpg\"\n",
    "\n",
    "# Analizar la imagen para obtener información de edad, género y emoción\n",
    "info_comparar = DeepFace.analyze(imagen_a_comparar, enforce_detection=False, actions=['age', 'gender', 'emotion'])[0]\n",
    "edad_comparar = info_comparar['age']\n",
    "genero_comparar = info_comparar['dominant_gender']\n",
    "emocion_comparar = info_comparar['dominant_emotion']\n",
    "\n",
    "# Iterar sobre cada categoría (persona) en el repositorio\n",
    "# Iterar sobre cada archivo en la carpeta de referencia\n",
    "for archivo_referencia in archivos_referencia:\n",
    "    # Ruta completa a la imagen de referencia de la persona\n",
    "    imagen_referencia = os.path.join(carpeta_referencia, archivo_referencia)\n",
    "    imagen_referencia = imagen_referencia.replace(\"\\\\\", \"/\")\n",
    "\n",
    "    # Analizar la imagen de referencia para obtener información de edad, género y emoción\n",
    "    info_referencia = DeepFace.analyze(imagen_referencia, enforce_detection=False, actions=['age', 'gender', 'emotion'])[0]\n",
    "    edad_referencia = info_referencia['age']\n",
    "    genero_referencia = info_referencia['dominant_gender']\n",
    "\n",
    "    # Calcular la diferencia en edad y género (otorgando pesos según la importancia)\n",
    "    diff_edad = abs(edad_comparar - edad_referencia)\n",
    "    peso_edad = 0.5\n",
    "    diff_genero = 0 if genero_comparar.lower() == genero_referencia.lower() else 1\n",
    "    peso_genero = 0.5\n",
    "\n",
    "    # Realizar la comparación de similitud\n",
    "    result = DeepFace.verify(imagen_a_comparar, imagen_referencia, model_name='Facenet', distance_metric='euclidean_l2', enforce_detection=False)\n",
    "    distancia_facial = result[\"distance\"]\n",
    "\n",
    "    # Calcular la similitud total basada en la diferencia de edad, género y la distancia facial\n",
    "    similitud = peso_edad * diff_edad + distancia_facial # + peso_genero * diff_genero\n",
    "\n",
    "    # Actualizar si encontramos una similitud menor\n",
    "    if similitud < distancia_minima:\n",
    "        distancia_minima = similitud\n",
    "        persona_mas_parecida = os.path.splitext(archivo_referencia)[0]  # Eliminar la extensión para obtener la categoría\n",
    "\n",
    "# Cargar la imagen del actor/actriz más parecido\n",
    "imagen_act_referencia = cv2.imread(os.path.join(carpeta_referencia, f\"{persona_mas_parecida}.jpg\"))\n",
    "\n",
    "# Mostrar la imagen en la parte superior del fotograma\n",
    "if imagen_act_referencia is not None:\n",
    "    cv2.imshow('Actor/Actriz Más Parecido(a)', imagen_act_referencia)\n",
    "\n",
    "# Liberar la captura de la cámara\n",
    "cap.release()\n",
    "\n",
    "# Mostrar el resultado en el fotograma\n",
    "# cv2.putText(frame, f\"Persona mas parecida: {persona_mas_parecida}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "# cv2.putText(frame, f\"Similitud total: {distancia_minima}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "# cv2.putText(frame, f\"Edad: {edad_comparar}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "# cv2.putText(frame, f\"Emoción: {emocion_comparar}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "cv2.imshow('Comparación de caras', frame)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f\"La persona más parecida es {persona_mas_parecida} con una similitud total de {distancia_minima}\")\n",
    "\n",
    "# Eliminar la imagen temporal al finalizar\n",
    "os.remove(\"imagen_temporal.jpg\")\n",
    "\n",
    "# Esperar hasta que se presione una tecla y cerrar todas las ventanas\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookalike search with memes (video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 3/3 [00:03<00:00,  1.07s/it]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  3.75it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.61it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.18it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.36it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.42it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.91it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.75it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.79it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.90it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.85it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.43it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ruta al directorio que contiene las carpetas de categorías (personas)\n",
    "carpeta_referencia = \"./Datasets/memes/\"\n",
    "\n",
    "imagen_por_defecto_path = './Datasets/memes/default.png'\n",
    "\n",
    "\n",
    "# Obtener la lista de categorías (nombres de personas)\n",
    "archivos_referencia = os.listdir(carpeta_referencia)\n",
    "\n",
    "# Tamaño de la imagen después de redimensionar\n",
    "resize_width = 320\n",
    "resize_height = 240\n",
    "\n",
    "# Inicializar variables para el resultado final\n",
    "persona_mas_parecida = None\n",
    "distancia_minima = float('inf')\n",
    "img_persona_parecida = None\n",
    "\n",
    "# Inicializar la captura de la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Lock para asegurar acceso seguro a las variables compartidas\n",
    "frame_lock = threading.Lock()\n",
    "result_lock = threading.Lock()\n",
    "\n",
    "frame_queue = queue.Queue(maxsize=1)\n",
    "result_info_queue = queue.Queue(maxsize=1)\n",
    "\n",
    "# Variable de evento para notificar a los hilos que deben finalizar\n",
    "exit_event = threading.Event()\n",
    "\n",
    "# Variables compartidas entre hilos\n",
    "frame = None\n",
    "result_info = None\n",
    "\n",
    "def read_camera():\n",
    "    global frame, persona_mas_parecida, persona_anterior, index_referencia\n",
    "    persona_mas_parecida = None  # Inicializa persona_mas_parecida antes del bucle\n",
    "    img_persona_parecida = None \n",
    "\n",
    "    while not exit_event.is_set():\n",
    "        ret, current_frame = cap.read()\n",
    "        if ret and current_frame is not None:\n",
    "            with frame_lock:\n",
    "                frame = cv2.resize(current_frame, (resize_width, resize_height))\n",
    "            try:\n",
    "                frame_queue.put_nowait(frame)\n",
    "            except queue.Full:\n",
    "                pass\n",
    "            # Display the real-time camera frame\n",
    "            cv2.imshow('Camera Frame', frame)\n",
    "        else:\n",
    "            print(\"Error: Failed to capture frame from the camera.\")\n",
    "\n",
    "        # Visualizar el texto en la imagen principal\n",
    "        with result_lock:\n",
    "            try:\n",
    "                if persona_mas_parecida is not None:\n",
    "                    # Si la persona más parecida ha cambiado desde la iteración anterior, cargar la nueva imagen\n",
    "                    if index_referencia == 0:\n",
    "                        img_persona_parecida_path = os.path.join(carpeta_referencia, f\"{persona_mas_parecida}.jpg\").replace(\"\\\\\", \"/\")\n",
    "                        img_persona_parecida = cv2.resize(cv2.imread(img_persona_parecida_path), (resize_width, resize_height))\n",
    "                    if img_persona_parecida is not None:\n",
    "                        cv2.imshow('Persona más parecida', img_persona_parecida)\n",
    "                else:\n",
    "                    img_por_defecto = cv2.resize(cv2.imread(imagen_por_defecto_path), (resize_width, resize_height))\n",
    "                    cv2.imshow('Persona más parecida', img_por_defecto)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al mostrar imágenes: {e}\")\n",
    "\n",
    "        # Salir del bucle si se presiona 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "def process_image():\n",
    "    global persona_mas_parecida, distancia_minima, result_info, index_referencia\n",
    "\n",
    "    # Inicializar el índice\n",
    "    index_referencia = 0\n",
    "\n",
    "    while not exit_event.is_set():\n",
    "        try:\n",
    "            frame = frame_queue.get_nowait()\n",
    "        except queue.Empty:\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "\n",
    "        cv2.imwrite(\"imagen_temporal.jpg\", frame)\n",
    "        imagen_a_comparar = \"imagen_temporal.jpg\"\n",
    "\n",
    "        # Redimensionar la imagen a comparar\n",
    "        img_comparar = cv2.resize(cv2.imread(imagen_a_comparar), (resize_width, resize_height))\n",
    "\n",
    "        # Analizar la imagen para obtener información de edad, género y emoción\n",
    "        info_comparar = DeepFace.analyze(img_comparar, enforce_detection=False, actions=['age', 'gender', 'emotion'])[0]\n",
    "        edad_comparar = info_comparar['age']\n",
    "        genero_comparar = info_comparar['dominant_gender']\n",
    "\n",
    "        # Reinicializar variables antes de la comparación\n",
    "        with result_lock:\n",
    "            distancia_minima = float('inf')\n",
    "            persona_mas_parecida = None\n",
    "\n",
    "        # Iterar sobre cada categoría (persona) en el repositorio\n",
    "        while index_referencia < len(archivos_referencia):\n",
    "            archivo_referencia = archivos_referencia[index_referencia]\n",
    "            imagen_referencia = os.path.join(carpeta_referencia, archivo_referencia).replace(\"\\\\\", \"/\")\n",
    "\n",
    "            # Redimensionar la imagen de referencia\n",
    "            img_referencia = cv2.resize(cv2.imread(imagen_referencia), (resize_width, resize_height))\n",
    "\n",
    "            # Analizar la imagen de referencia para obtener información de edad, género y emoción\n",
    "            info_referencia = DeepFace.analyze(img_referencia, enforce_detection=False, actions=['age', 'gender', 'emotion'])[0]\n",
    "            edad_referencia = info_referencia['age']\n",
    "            genero_referencia = info_referencia['dominant_gender']\n",
    "\n",
    "            # Calcular la diferencia en edad y género (otorgando pesos según la importancia)\n",
    "            diff_edad = abs(edad_comparar - edad_referencia)\n",
    "            peso_edad = 0.5\n",
    "            diff_genero = 0 if genero_comparar.lower() == genero_referencia.lower() else 1\n",
    "            peso_genero = 0.5\n",
    "\n",
    "            # Realizar la comparación de similitud\n",
    "            result = DeepFace.verify(img_comparar, img_referencia, model_name='Facenet', distance_metric='euclidean_l2', enforce_detection=False)\n",
    "            distancia_facial = result[\"distance\"]\n",
    "\n",
    "            # Calcular la similitud total basada en la diferencia de edad, género y la distancia facial\n",
    "            similitud = peso_edad * diff_edad + peso_genero * diff_genero + distancia_facial\n",
    "\n",
    "            # Actualizar si encontramos una similitud menor\n",
    "            with result_lock:\n",
    "                if similitud < distancia_minima:\n",
    "                    distancia_minima = similitud\n",
    "                    persona_mas_parecida = os.path.splitext(archivo_referencia)[0]  # Eliminar la extensión para obtener la categoría\n",
    "\n",
    "            # Incrementar el índice\n",
    "            index_referencia += 1\n",
    "\n",
    "        # Reiniciar el índice para la próxima iteración\n",
    "        index_referencia = 0\n",
    "        # Esperar 5 segundos antes de realizar la próxima comparación\n",
    "        time.sleep(5)\n",
    "\n",
    "# Inicia los hilos\n",
    "camera_thread = threading.Thread(target=read_camera)\n",
    "camera_thread.daemon = True\n",
    "camera_thread.start()\n",
    "\n",
    "process_thread = threading.Thread(target=process_image)\n",
    "process_thread.daemon = True\n",
    "process_thread.start()\n",
    "\n",
    "# Espera a que los hilos se inicien completamente\n",
    "time.sleep(2)\n",
    "\n",
    "# Espera a que se presione 'q' para salir del programa\n",
    "while True:\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        exit_event.set()  # Establecer el evento para notificar a los hilos que deben finalizar\n",
    "        break\n",
    "\n",
    "# Espera a que los hilos finalicen\n",
    "camera_thread.join()\n",
    "process_thread.join()\n",
    "\n",
    "# Liberar la captura de la cámara y cerrar todas las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Eliminar la imagen temporal al finalizar\n",
    "os.remove(\"imagen_temporal.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_fixed_opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
