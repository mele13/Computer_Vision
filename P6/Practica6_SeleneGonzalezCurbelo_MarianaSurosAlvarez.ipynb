{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Mele\\anaconda3\\envs\\conda_env_fixed_opencv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "from deepface import DeepFace\n",
    "import threading\n",
    "import time\n",
    "import queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools & tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating samples folder (celebrities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './Datasets/famosos'\n",
    "\n",
    "for directory in os.listdir(data_dir):\n",
    "    first_file = os.listdir(os.path.join(data_dir, directory))[0]\n",
    "    shutil.copyfile(os.path.join(data_dir, directory, first_file), os.path.join(\"Samples\", f\"{directory}.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookalike test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = DeepFace.verify(\"person1.jpg\", f\"Samples/Angelina Jolie.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verified': False,\n",
       " 'distance': 0.7698307337090413,\n",
       " 'threshold': 0.4,\n",
       " 'model': 'VGG-Face',\n",
       " 'detector_backend': 'opencv',\n",
       " 'similarity_metric': 'cosine',\n",
       " 'facial_areas': {'img1': {'x': 208, 'y': 37, 'w': 120, 'h': 120},\n",
       "  'img2': {'x': 74, 'y': 115, 'w': 287, 'h': 287}},\n",
       " 'time': 0.54}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age, render & race test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 4/4 [00:00<00:00,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'age': 29, 'region': {'x': 208, 'y': 37, 'w': 120, 'h': 120}, 'gender': {'Woman': 4.4589015146812017e-05, 'Man': 99.99995231628418}, 'dominant_gender': 'Man', 'race': {'asian': 0.32646742183715105, 'indian': 7.5354211032390594, 'black': 0.32972635235637426, 'white': 32.79293179512024, 'middle eastern': 32.33891725540161, 'latino hispanic': 26.676541566848755}, 'dominant_race': 'white', 'emotion': {'angry': 3.388790208301382e-08, 'disgust': 5.378273185664511e-13, 'fear': 9.986144302869349e-06, 'happy': 96.66207989002227, 'sad': 2.6955637382574697e-06, 'surprise': 0.008525826995080203, 'neutral': 3.329385841415625}, 'dominant_emotion': 'happy'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "emotionImg = cv2.imread('./person1.jpg')\n",
    "obj = DeepFace.analyze(emotionImg, enforce_detection=False, actions=['age', 'gender', 'race', 'emotion'])\n",
    "\n",
    "print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookalike search with celebrities (images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No exact match found! Closest match is Hugh Jackman\n"
     ]
    }
   ],
   "source": [
    "smallest_distance = None\n",
    "\n",
    "for file in os.listdir(\"Samples\"):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        # result = DeepFace.verify(\"./Images/person1.jpg\", f\"Samples/{file}\")\n",
    "        # result = DeepFace.verify(\"./Images/person2.jpg\", f\"Samples/{file}\")\n",
    "        result = DeepFace.verify(\"./Images/match.jpg\", f\"Samples/{file}\")\n",
    "        if result['verified']:\n",
    "            print(\"This person looks exactly like\", file.split(\".\")[0])\n",
    "            break\n",
    "        if smallest_distance is None: # First instance\n",
    "            smallest_distance = (file.split(\".\")[0], result['distance'])\n",
    "        else:\n",
    "            smallest_distance = (file.split(\".\")[0], result['distance']) if result['distance'] < smallest_distance[1] else smallest_distance\n",
    "else:\n",
    "    print(f\"No exact match found! Closest match is {smallest_distance[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookalike search with celebrities (video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 3/3 [00:01<00:00,  2.07it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.48it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.78it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.69it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.68it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.77it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.74it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.71it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.57it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.60it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.91it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.70it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.68it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.63it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.80it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.71it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.79it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La persona más parecida es Sandra Bullock con una similitud total de 1.316648349942769\n"
     ]
    }
   ],
   "source": [
    "# Ruta al directorio que contiene las carpetas de categorías (personas)\n",
    "carpeta_referencia = \"./Samples\"\n",
    "\n",
    "# Obtener la lista de categorías (nombres de personas)\n",
    "archivos_referencia = os.listdir(carpeta_referencia)\n",
    "\n",
    "# Inicializar variables para el resultado final\n",
    "persona_mas_parecida = None\n",
    "distancia_minima = float('inf')\n",
    "\n",
    "# Inicializar la captura de la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Capturar el fotograma de la cámara\n",
    "ret, frame = cap.read()\n",
    "frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "# Guardar la imagen temporal\n",
    "cv2.imwrite(\"imagen_temporal.jpg\", frame)\n",
    "imagen_a_comparar = \"imagen_temporal.jpg\"\n",
    "\n",
    "# Analizar la imagen para obtener información de edad, género y emoción\n",
    "info_comparar = DeepFace.analyze(imagen_a_comparar, enforce_detection=False, actions=['age', 'gender', 'emotion'])[0]\n",
    "edad_comparar = info_comparar['age']\n",
    "genero_comparar = info_comparar['dominant_gender']\n",
    "emocion_comparar = info_comparar['dominant_emotion']\n",
    "\n",
    "# Iterar sobre cada categoría (persona) en el repositorio\n",
    "# Iterar sobre cada archivo en la carpeta de referencia\n",
    "for archivo_referencia in archivos_referencia:\n",
    "    # Ruta completa a la imagen de referencia de la persona\n",
    "    imagen_referencia = os.path.join(carpeta_referencia, archivo_referencia)\n",
    "    imagen_referencia = imagen_referencia.replace(\"\\\\\", \"/\")\n",
    "\n",
    "    # Analizar la imagen de referencia para obtener información de edad, género y emoción\n",
    "    info_referencia = DeepFace.analyze(imagen_referencia, enforce_detection=False, actions=['age', 'gender', 'emotion'])[0]\n",
    "    edad_referencia = info_referencia['age']\n",
    "    genero_referencia = info_referencia['dominant_gender']\n",
    "\n",
    "    # Calcular la diferencia en edad y género (otorgando pesos según la importancia)\n",
    "    diff_edad = abs(edad_comparar - edad_referencia)\n",
    "    peso_edad = 0.5\n",
    "    diff_genero = 0 if genero_comparar.lower() == genero_referencia.lower() else 1\n",
    "    peso_genero = 0.5\n",
    "\n",
    "    # Realizar la comparación de similitud\n",
    "    result = DeepFace.verify(imagen_a_comparar, imagen_referencia, model_name='Facenet', distance_metric='euclidean_l2', enforce_detection=False)\n",
    "    distancia_facial = result[\"distance\"]\n",
    "\n",
    "    # Calcular la similitud total basada en la diferencia de edad, género y la distancia facial\n",
    "    similitud = peso_edad * diff_edad + distancia_facial # + peso_genero * diff_genero\n",
    "\n",
    "    # Actualizar si encontramos una similitud menor\n",
    "    if similitud < distancia_minima:\n",
    "        distancia_minima = similitud\n",
    "        persona_mas_parecida = os.path.splitext(archivo_referencia)[0]  # Eliminar la extensión para obtener la categoría\n",
    "\n",
    "# Cargar la imagen del actor/actriz más parecido\n",
    "imagen_act_referencia = cv2.imread(os.path.join(carpeta_referencia, f\"{persona_mas_parecida}.jpg\"))\n",
    "\n",
    "# Mostrar la imagen en la parte superior del fotograma\n",
    "if imagen_act_referencia is not None:\n",
    "    cv2.imshow('Actor/Actriz Más Parecido(a)', imagen_act_referencia)\n",
    "\n",
    "# Liberar la captura de la cámara\n",
    "cap.release()\n",
    "\n",
    "# Mostrar el resultado en el fotograma\n",
    "# cv2.putText(frame, f\"Persona mas parecida: {persona_mas_parecida}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "# cv2.putText(frame, f\"Similitud total: {distancia_minima}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "# cv2.putText(frame, f\"Edad: {edad_comparar}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "# cv2.putText(frame, f\"Emoción: {emocion_comparar}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "cv2.imshow('Comparación de caras', frame)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f\"La persona más parecida es {persona_mas_parecida} con una similitud total de {distancia_minima}\")\n",
    "\n",
    "# Eliminar la imagen temporal al finalizar\n",
    "os.remove(\"imagen_temporal.jpg\")\n",
    "\n",
    "# Esperar hasta que se presione una tecla y cerrar todas las ventanas\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookalike search with memes (video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter by distance and then by emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion: 100%|██████████| 3/3 [00:03<00:00,  1.07s/it]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  3.75it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.61it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.18it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.36it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.42it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.91it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.75it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.79it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.90it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.85it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.43it/s]\n",
      "Action: emotion: 100%|██████████| 3/3 [00:00<00:00,  5.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Ruta al directorio que contiene las carpetas de categorías (personas)\n",
    "reference_folder = \"./Datasets/memes/\"\n",
    "\n",
    "# Path to the default image\n",
    "default_image_path = './Images/default.jpg'\n",
    "\n",
    "# Image resize dimensions\n",
    "resize_width = 320\n",
    "resize_height = 240\n",
    "\n",
    "# Initialize variables for the final result\n",
    "most_similar_person = None\n",
    "min_distance = float('inf')\n",
    "emocion_diff_anterior = float('inf')\n",
    "similar_image = None\n",
    "\n",
    "# Initialize camera capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Lock for ensuring safe access to shared variables\n",
    "frame_lock = threading.Lock()\n",
    "result_lock = threading.Lock()\n",
    "\n",
    "frame_queue = queue.Queue(maxsize=1)\n",
    "result_info_queue = queue.Queue(maxsize=1)\n",
    "\n",
    "# Event variable to notify threads to terminate\n",
    "exit_event = threading.Event()\n",
    "\n",
    "# Shared variables between threads\n",
    "frame = None\n",
    "result_info = None\n",
    "index_referencia = 0\n",
    "\n",
    "def read_camera():\n",
    "    global frame, most_similar_person, index_referencia\n",
    "    most_similar_person = None \n",
    "    similar_image = None \n",
    "\n",
    "    while not exit_event.is_set():\n",
    "        ret, current_frame = cap.read()\n",
    "        if ret and current_frame is not None:\n",
    "            with frame_lock:\n",
    "                frame = cv2.resize(current_frame, (resize_width, resize_height))\n",
    "            try:\n",
    "                frame_queue.put_nowait(frame)\n",
    "            except queue.Full:\n",
    "                pass\n",
    "            cv2.imshow('Camera Frame', frame)\n",
    "\n",
    "        with result_lock:\n",
    "            try:\n",
    "                if most_similar_person is not None:\n",
    "                    # Si la persona más parecida ha cambiado desde la iteración anterior, cargar la nueva imagen\n",
    "                    if index_referencia == 0:\n",
    "                        similar_image_path = os.path.join(reference_folder, f\"{most_similar_person}.jpg\").replace(\"\\\\\", \"/\")\n",
    "                        similar_image = cv2.resize(cv2.imread(similar_image_path), (resize_width, resize_height))\n",
    "                    if similar_image is not None:\n",
    "                        cv2.imshow('Persona más parecida', similar_image)\n",
    "                else:\n",
    "                    default_img = cv2.resize(cv2.imread(default_image_path), (resize_width, resize_height))\n",
    "                    cv2.imshow('Persona más parecida', default_img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al mostrar imágenes: {e}\")\n",
    "\n",
    "        # Exit the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "def process_image():\n",
    "    global most_similar_person, min_distance, index_referencia\n",
    "\n",
    "    while not exit_event.is_set():\n",
    "        try:\n",
    "            frame = frame_queue.get_nowait()\n",
    "        except queue.Empty:\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "\n",
    "        cv2.imwrite(\"temp_image.jpg\", frame)\n",
    "        image_to_compare = \"temp_image.jpg\"\n",
    "\n",
    "        # Muestra la imagen que se está comparando en el hilo process_image\n",
    "        img_compare = cv2.resize(cv2.imread(image_to_compare), (resize_width, resize_height))\n",
    "        cv2.imshow('Image to Compare in process_image', img_compare)\n",
    "        cv2.waitKey(1)  # Necesario para que OpenCV muestre la imagen\n",
    "\n",
    "        if img_compare is None or img_compare.size == 0:\n",
    "            print(\"Error: img_compare is None or empty.\")\n",
    "            continue\n",
    "        # Initialize variables before comparison\n",
    "        # Analizar emociones primero\n",
    "        with result_lock:\n",
    "            min_distance = float('inf')\n",
    "            emocion_diff_anterior = float('inf')\n",
    "            most_similar_person = None\n",
    "\n",
    "        info_comparar = DeepFace.analyze(img_compare, enforce_detection=False, actions=['age', 'gender', 'emotion'])[0]\n",
    "        emociones_comparar = info_comparar['emotion']\n",
    "        emocion_comparar = max(emociones_comparar.values())\n",
    "\n",
    "        valores_emociones_comparar = list(emociones_comparar.values())\n",
    "        print(valores_emociones_comparar)\n",
    "        # Encuentra la posición (índice) de emocion_comparar en la lista de valores\n",
    "        posicion_emocion_comparar = valores_emociones_comparar.index(emocion_comparar)\n",
    "        emociones_comparar_lista = list(emociones_comparar.keys())\n",
    "        emocion_aja = emociones_comparar_lista[posicion_emocion_comparar]\n",
    "        # Imprime la posición\n",
    "        print(f\"Posición de {emocion_comparar} en la lista de valores: {emocion_aja}\")\n",
    "\n",
    "\n",
    "        # Iterar sobre cada referencia\n",
    "        for reference_file in os.listdir(reference_folder):\n",
    "            reference_image_path = os.path.join(reference_folder, reference_file)\n",
    "            img_reference = cv2.resize(cv2.imread(reference_image_path), (resize_width, resize_height))\n",
    "            if img_reference is None or img_reference.size == 0:\n",
    "                print(f\"Error: img_reference ({reference_file}) is None or empty.\")\n",
    "                continue\n",
    "\n",
    "            # Analizar emociones de la imagen de referencia\n",
    "            info_referencia = DeepFace.analyze(img_reference, enforce_detection=False, actions=['age', 'gender', 'emotion'])[0]\n",
    "            emociones_referencia = info_referencia['emotion']\n",
    "            emocion_referencia = max(emociones_referencia.values())\n",
    "\n",
    "            # Comparación de emociones antes de la comparación facial\n",
    "            with result_lock:\n",
    "                emocion_diff_nueva = abs(emocion_comparar - emocion_referencia)\n",
    "                if emocion_diff_nueva < emocion_diff_anterior:\n",
    "                    emocion_diff_anterior = emocion_diff_nueva\n",
    "                    most_similar_person = os.path.splitext(reference_file)[0]\n",
    "\n",
    "                    # Comparación facial después de la comparación de emociones\n",
    "                    result = DeepFace.verify(img_compare, img_reference, model_name='Facenet', distance_metric='euclidean_l2', enforce_detection=False)\n",
    "                    facial_distance = result[\"distance\"]\n",
    "\n",
    "                    # Actualizar si se encuentra una distancia facial más pequeña\n",
    "                    if facial_distance > min_distance:\n",
    "                        min_distance = facial_distance\n",
    "                        most_similar_person = os.path.splitext(reference_file)[0]\n",
    "        \n",
    "            index_referencia += 1\n",
    "\n",
    "        # Reiniciar el índice para la próxima iteración\n",
    "        index_referencia = 0\n",
    "        # Wait for 5 seconds before the next comparison\n",
    "        time.sleep(5)\n",
    "\n",
    "# Start threads\n",
    "camera_thread = threading.Thread(target=read_camera)\n",
    "camera_thread.daemon = True\n",
    "camera_thread.start()\n",
    "\n",
    "process_thread = threading.Thread(target=process_image)\n",
    "process_thread.daemon = True\n",
    "process_thread.start()\n",
    "\n",
    "# Wait for threads to start completely\n",
    "time.sleep(2)\n",
    "\n",
    "# Wait for 'q' key to exit the program\n",
    "while True:\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        exit_event.set()  # Set the event to notify threads to terminate\n",
    "        break\n",
    "\n",
    "# Wait for threads to finish\n",
    "camera_thread.join()\n",
    "process_thread.join()\n",
    "\n",
    "# Release camera capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Eliminar la imagen temporal al finalizar\n",
    "os.remove(\"temp_image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter by emotion and then by distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path containing reference images\n",
    "reference_folder = \"./Memes\"\n",
    "\n",
    "# Path to the default image\n",
    "default_image_path = './default.jpg'\n",
    "\n",
    "# Image resize dimensions\n",
    "resize_width = 320\n",
    "resize_height = 240\n",
    "\n",
    "# Initialize variables for the final result\n",
    "most_similar_person = None\n",
    "min_distance = float('inf')\n",
    "emocion_diff_anterior = float('inf')\n",
    "similar_image = None\n",
    "\n",
    "# Initialize camera capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Lock for ensuring safe access to shared variables\n",
    "frame_lock = threading.Lock()\n",
    "result_lock = threading.Lock()\n",
    "\n",
    "frame_queue = queue.Queue(maxsize=1)\n",
    "result_info_queue = queue.Queue(maxsize=1)\n",
    "\n",
    "# Event variable to notify threads to terminate\n",
    "exit_event = threading.Event()\n",
    "\n",
    "# Shared variables between threads\n",
    "frame = None\n",
    "result_info = None\n",
    "index_referencia = 0\n",
    "\n",
    "def read_camera():\n",
    "    global frame, most_similar_person, index_referencia\n",
    "    most_similar_person = None \n",
    "    similar_image = None \n",
    "\n",
    "    while not exit_event.is_set():\n",
    "        ret, current_frame = cap.read()\n",
    "        if ret and current_frame is not None:\n",
    "            with frame_lock:\n",
    "                frame = cv2.resize(current_frame, (resize_width, resize_height))\n",
    "            try:\n",
    "                frame_queue.put_nowait(frame)\n",
    "            except queue.Full:\n",
    "                pass\n",
    "            cv2.imshow('Camera Frame', frame)\n",
    "\n",
    "        with result_lock:\n",
    "            try:\n",
    "                if most_similar_person is not None:\n",
    "                    # Si la persona más parecida ha cambiado desde la iteración anterior, cargar la nueva imagen\n",
    "                    if index_referencia == 0:\n",
    "                        similar_image_path = os.path.join(reference_folder, f\"{most_similar_person}.jpg\").replace(\"\\\\\", \"/\")\n",
    "                        similar_image = cv2.resize(cv2.imread(similar_image_path), (resize_width, resize_height))\n",
    "                    if similar_image is not None:\n",
    "                        cv2.imshow('Persona más parecida', similar_image)\n",
    "                else:\n",
    "                    default_img = cv2.resize(cv2.imread(default_image_path), (resize_width, resize_height))\n",
    "                    cv2.imshow('Persona más parecida', default_img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error al mostrar imágenes: {e}\")\n",
    "\n",
    "        # Exit the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "def process_image():\n",
    "    global most_similar_person, min_distance, index_referencia\n",
    "\n",
    "    while not exit_event.is_set():\n",
    "        try:\n",
    "            frame = frame_queue.get_nowait()\n",
    "        except queue.Empty:\n",
    "            time.sleep(0.1)\n",
    "            continue\n",
    "\n",
    "        cv2.imwrite(\"temp_image.jpg\", frame)\n",
    "        image_to_compare = \"temp_image.jpg\"\n",
    "\n",
    "        # Muestra la imagen que se está comparando en el hilo process_image\n",
    "        img_compare = cv2.resize(cv2.imread(image_to_compare), (resize_width, resize_height))\n",
    "        cv2.imshow('Image to Compare in process_image', img_compare)\n",
    "        cv2.waitKey(1)  # Necesario para que OpenCV muestre la imagen\n",
    "\n",
    "        if img_compare is None or img_compare.size == 0:\n",
    "            print(\"Error: img_compare is None or empty.\")\n",
    "            continue\n",
    "        # Initialize variables before comparison\n",
    "        with result_lock:\n",
    "            min_distance = float('inf')\n",
    "            emocion_diff_anterior = float('inf')\n",
    "            most_similar_person = None\n",
    "\n",
    "        # Iterate over each reference image in the repository\n",
    "        for reference_file in os.listdir(reference_folder):\n",
    "            reference_image_path = os.path.join(reference_folder, reference_file)\n",
    "\n",
    "            # Resize the reference image\n",
    "            img_reference = cv2.resize(cv2.imread(reference_image_path), (resize_width, resize_height))\n",
    "            if img_reference is None or img_reference.size == 0:\n",
    "                print(f\"Error: img_reference ({reference_file}) is None or empty.\")\n",
    "                continue\n",
    "\n",
    "            info_referencia = DeepFace.analyze(img_reference, enforce_detection=False, actions=['age', 'gender', 'emotion'])[0]\n",
    "            #edad_referencia = info_referencia['age']\n",
    "            #genero_referencia = info_referencia['dominant_gender']\n",
    "            emociones_referencia = info_referencia['emotion']\n",
    "            emocion_referencia = max(emociones_referencia.values())\n",
    "\n",
    "            # Perform face recognition similarity comparison\n",
    "            result = DeepFace.verify(img_compare, img_reference, model_name='Facenet', distance_metric='euclidean_l2', enforce_detection=False)\n",
    "            \n",
    "            facial_distance = result[\"distance\"]\n",
    "\n",
    "            # Update if a smaller distance is found\n",
    "            with result_lock:\n",
    "                if facial_distance < min_distance:\n",
    "                    min_distance = facial_distance\n",
    "                    info_referencia = DeepFace.analyze(img_reference, enforce_detection=False, actions=['age', 'gender', 'emotion'])[0]\n",
    "                    most_similar_person = os.path.splitext(reference_file)[0]\n",
    "                if facial_distance == min_distance:\n",
    "                    info_comparar = DeepFace.analyze(img_compare, enforce_detection=False, actions=['age', 'gender', 'emotion'])[0]\n",
    "                    emociones_comparar = info_comparar['emotion']\n",
    "                    emocion_comparar = max(emociones_comparar.values())\n",
    "                    # Obtén la lista de valores (intensidades de emociones)\n",
    "                    valores_emociones_comparar = list(emociones_comparar.values())\n",
    "                    print(valores_emociones_comparar)\n",
    "                    # Encuentra la posición (índice) de emocion_comparar en la lista de valores\n",
    "                    posicion_emocion_comparar = valores_emociones_comparar.index(emocion_comparar)\n",
    "                    emociones_comparar_lista = list(emociones_comparar.keys())\n",
    "                    emocion_aja = emociones_comparar_lista[posicion_emocion_comparar]\n",
    "                    # Imprime la posición\n",
    "                    print(f\"Posición de {emocion_comparar} en la lista de valores: {emocion_aja}\")\n",
    "\n",
    "\n",
    "                    # Ensure the data types are compatible before subtraction\n",
    "                    emocion_referencia = float(emocion_referencia)\n",
    "                    emocion_diff_nueva = abs(emocion_comparar - emocion_referencia)\n",
    "                    if emocion_diff_nueva > emocion_diff_anterior:\n",
    "                        print(\"mejor emocion\")\n",
    "                        emocion_diff_anterior = emocion_diff_nueva\n",
    "                        most_similar_person = os.path.splitext(reference_file)[0]\n",
    "\n",
    "            index_referencia += 1\n",
    "\n",
    "        # Reiniciar el índice para la próxima iteración\n",
    "        index_referencia = 0\n",
    "        # Wait for 5 seconds before the next comparison\n",
    "        time.sleep(5)\n",
    "\n",
    "# Start threads\n",
    "camera_thread = threading.Thread(target=read_camera)\n",
    "camera_thread.daemon = True\n",
    "camera_thread.start()\n",
    "\n",
    "process_thread = threading.Thread(target=process_image)\n",
    "process_thread.daemon = True\n",
    "process_thread.start()\n",
    "\n",
    "# Wait for threads to start completely\n",
    "time.sleep(2)\n",
    "\n",
    "# Wait for 'q' key to exit the program\n",
    "while True:\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        exit_event.set()  # Set the event to notify threads to terminate\n",
    "        break\n",
    "\n",
    "# Wait for threads to finish\n",
    "camera_thread.join()\n",
    "process_thread.join()\n",
    "\n",
    "# Release camera capture and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "os.remove(\"temp_image.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_env_fixed_opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
