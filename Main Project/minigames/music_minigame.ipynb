{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q mediapipe==0.10.0\n",
    "#!curl -o pose_landmarker.task -sSL https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_heavy/float16/1/pose_landmarker_heavy.task\n",
    "#!curl -o image.jpg -sSL https://cdn.pixabay.com/photo/2019/03/12/20/39/girl-4051811_960_720.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No file 'sounds/base.mp3' found in working directory 'e:\\VC\\P7\\minigames'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m background_music_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msounds/base.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m pygame\u001b[38;5;241m.\u001b[39mmixer\u001b[38;5;241m.\u001b[39minit()\n\u001b[1;32m---> 13\u001b[0m background_music \u001b[38;5;241m=\u001b[39m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackground_music_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Set the initial volume for background music\u001b[39;00m\n\u001b[0;32m     16\u001b[0m background_music_volume \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No file 'sounds/base.mp3' found in working directory 'e:\\VC\\P7\\minigames'."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pygame\n",
    "from math import acos, degrees\n",
    "\n",
    "# Initialize pygame\n",
    "pygame.init()\n",
    "\n",
    "# Load the background music file\n",
    "background_music_file = \"sounds/base.mp3\"\n",
    "pygame.mixer.init()\n",
    "background_music = pygame.mixer.Sound(background_music_file)\n",
    "\n",
    "# Set the initial volume for background music\n",
    "background_music_volume = 0.3\n",
    "background_music.set_volume(background_music_volume)\n",
    "\n",
    "# Load the sound file you want to play on pose detection\n",
    "sound_files = [\n",
    "    \"sounds/sound1.mp3\",\n",
    "    \"sounds/sound2.mp3\",\n",
    "    \"sounds/sound3.mp3\",\n",
    "    \"sounds/sound4.mp3\",\n",
    "    \"sounds/sound5.mp3\",\n",
    "    \"sounds/sound6.mp3\",\n",
    "    # Add more sound files as needed\n",
    "]\n",
    "\n",
    "\n",
    "# Create an array of sounds\n",
    "sounds = [pygame.mixer.Sound(file) for file in sound_files]\n",
    "\n",
    "# Set the initial volume for pose detection sound\n",
    "pose_detection_volume = 0.5\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "def play_music_game():\n",
    "    circle_exit_x, circle_exit_y = 40, 40 \n",
    "\n",
    "    # Pulgar\n",
    "    thumb_points = [1, 2, 4]\n",
    "    # Índice, medio, anular y meñique\n",
    "    palm_points = [0, 1, 2, 5, 9, 13, 17]\n",
    "    fingertips_points = [8, 12, 16, 20]\n",
    "    finger_base_points =[6, 10, 14, 18]\n",
    "    # FINGERS COMBINATIONS\n",
    "    TO_ACTIVATE = np.array([True, False, False, False, False])\n",
    "\n",
    "    # Images to show\n",
    "    image1 = cv2.imread(\"images/imagen_inicio.jpg\")\n",
    "    image2 = cv2.imread(\"images/instruccion_music.jpg\")\n",
    "\n",
    "    # Image to concat\n",
    "    imAux = image1\n",
    "\n",
    "    # For webcam input:\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    sound_playing = False\n",
    "    exit = False\n",
    "\n",
    "    sound_background_playing = False\n",
    "\n",
    "    with mp_pose.Pose(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as pose, mp_hands.Hands(\n",
    "        static_image_mode=False,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5) as hands:\n",
    "\n",
    "        hand_detection_active = True\n",
    "\n",
    "        while True:\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                continue\n",
    "            \n",
    "            image = cv2.flip(image, 1)\n",
    "            \n",
    "            if hand_detection_active:\n",
    "                # Process hands\n",
    "                image.flags.writeable = False\n",
    "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                height, width, _ = image.shape\n",
    "                results_hands = hands.process(image_rgb)\n",
    "                if results_hands.multi_hand_landmarks is not None:\n",
    "                    fingers = fingers_up_down(results_hands, thumb_points, palm_points, fingertips_points, finger_base_points, height, width, image)\n",
    "                    if not False in (fingers == TO_ACTIVATE):\n",
    "                        hand_detection_active = False\n",
    "            else:\n",
    "                # Process pose\n",
    "                if not sound_background_playing:\n",
    "                    background_music.play(-1) \n",
    "                    sound_background_playing = True\n",
    "\n",
    "                image.flags.writeable = False\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                results = pose.process(image)\n",
    "                if results.pose_landmarks is not None:  # Use pose_landmarks instead of multi_hand_landmarks\n",
    "                    image.flags.writeable = True\n",
    "                    image = np.zeros_like(image)\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image,\n",
    "                        results.pose_landmarks,\n",
    "                        mp_pose.POSE_CONNECTIONS,\n",
    "                        landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "                    center_coordinates = (image.shape[1] // 2, image.shape[0] // 2)\n",
    "                    radius = 230\n",
    "                    thickness = 2\n",
    "                    cv2.circle(image, center_coordinates, radius, (0, 255, 0), thickness)\n",
    "\n",
    "                    num_circles = min(len(sounds), 8)  # Use the minimum between the number of sounds and circles\n",
    "                    circle_radius = 35\n",
    "\n",
    "                    landmark_19_x, landmark_19_y, landmark_20_x, landmark_20_y, landmark_31_x, landmark_31_y, landmark_32_x, landmark_32_y = None, None, None, None, None, None, None, None  \n",
    "                    if results.pose_landmarks.landmark:\n",
    "                        landmark_19_x = int(results.pose_landmarks.landmark[19].x * image.shape[1])\n",
    "                        landmark_19_y = int(results.pose_landmarks.landmark[19].y * image.shape[0])\n",
    "                        landmark_20_x = int(results.pose_landmarks.landmark[20].x * image.shape[1])\n",
    "                        landmark_20_y = int(results.pose_landmarks.landmark[20].y * image.shape[0])\n",
    "                        landmark_31_x = int(results.pose_landmarks.landmark[31].x * image.shape[1])\n",
    "                        landmark_31_y = int(results.pose_landmarks.landmark[31].y * image.shape[0])\n",
    "                        landmark_32_x = int(results.pose_landmarks.landmark[32].x * image.shape[1])\n",
    "                        landmark_32_y = int(results.pose_landmarks.landmark[32].y * image.shape[0])\n",
    "\n",
    "                    cv2.circle(image, (circle_exit_x, circle_exit_y), circle_radius, (0, 255, 255), -1)\n",
    "                    cv2.putText(image, \"Exit\", (circle_exit_x - 15, circle_exit_y + 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "                    for i in range(num_circles):\n",
    "                        angle_rad = 2 * np.pi * i / num_circles\n",
    "                        circle_x = int(center_coordinates[0] + radius * np.cos(angle_rad))\n",
    "                        circle_y = int(center_coordinates[1] + radius * np.sin(angle_rad))\n",
    "                        cv2.circle(image, (circle_x, circle_y), circle_radius, (255, 0, 0), -1)\n",
    "\n",
    "                        distance_exit_19 = np.sqrt((landmark_19_x - circle_exit_x)**2 + (landmark_19_y - circle_exit_x)**2)\n",
    "                        distance_exit_20 = np.sqrt((landmark_20_x - circle_exit_x)**2 + (landmark_20_y - circle_exit_y)**2)\n",
    "                        threshold_distance = 30\n",
    "\n",
    "                        if distance_exit_19 < threshold_distance or distance_exit_20 < threshold_distance:\n",
    "                            exit = True\n",
    "                            break\n",
    "\n",
    "                        distance_19 = np.sqrt((landmark_19_x - circle_x)**2 + (landmark_19_y - circle_y)**2)\n",
    "                        distance_20 = np.sqrt((landmark_20_x - circle_x)**2 + (landmark_20_y - circle_y)**2)\n",
    "                        distance_31 = np.sqrt((landmark_31_x - circle_x)**2 + (landmark_31_y - circle_y)**2)\n",
    "                        distance_32 = np.sqrt((landmark_32_x - circle_x)**2 + (landmark_32_y - circle_y)**2)\n",
    "\n",
    "                        if distance_19 < threshold_distance or distance_20 < threshold_distance or distance_31 < threshold_distance or distance_32 < threshold_distance:\n",
    "                            if not sound_playing:\n",
    "                                sounds[i].play()  # Play the sound corresponding to the circle\n",
    "                                sounds[i].set_volume(pose_detection_volume)  # Set the volume\n",
    "                                sound_playing = True\n",
    "                        else:\n",
    "                            sound_playing = False\n",
    "\n",
    "            resized_image = cv2.resize(image, (800, 600))\n",
    "            if not hand_detection_active:\n",
    "                imAux = image2\n",
    "\n",
    "            if imAux.shape[0] != resized_image.shape[0]:\n",
    "                # Resize imAux to have the same number of rows as frame\n",
    "                imAux = cv2.resize(imAux, (resized_image.shape[1], resized_image.shape[0]))\n",
    "\n",
    "            # Concatenate images horizontally\n",
    "            n_image = cv2.hconcat([imAux, resized_image])\n",
    "\n",
    "            cv2.imshow(\"MediaPipe Pose\", n_image)\n",
    "            #cv2.imshow('MediaPipe Pose', resized_image)\n",
    "            if cv2.waitKey(5) & 0xFF == 27 or exit:\n",
    "                background_music.stop()  # Stop background music\n",
    "                break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def palm_centroid(coordinates_list):\n",
    "    coordinates = np.array(coordinates_list)\n",
    "    centroid = np.mean(coordinates, axis=0)\n",
    "    centroid = int(centroid[0]), int(centroid[1])\n",
    "    return centroid\n",
    "\n",
    "def fingers_up_down(hand_results, thumb_points, palm_points, fingertips_points, finger_base_points, height, width, frame):\n",
    "    fingers = None\n",
    "    if hand_results.multi_hand_landmarks:\n",
    "        coordinates_thumb = []\n",
    "        coordinates_palm = []\n",
    "        coordinates_ft = []  # Initialize as a Python list\n",
    "        coordinates_fb = []\n",
    "        for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "            for index in thumb_points:\n",
    "                x = int(hand_landmarks.landmark[index].x * width)\n",
    "                y = int(hand_landmarks.landmark[index].y * height)\n",
    "                coordinates_thumb.append([x, y])\n",
    "            \n",
    "            for index in palm_points:\n",
    "                x = int(hand_landmarks.landmark[index].x * width)\n",
    "                y = int(hand_landmarks.landmark[index].y * height)\n",
    "                coordinates_palm.append([x, y])\n",
    "            \n",
    "            for index in fingertips_points:\n",
    "                x = int(hand_landmarks.landmark[index].x * width)\n",
    "                y = int(hand_landmarks.landmark[index].y * height)\n",
    "                coordinates_ft.append([x, y])\n",
    "            \n",
    "            for index in finger_base_points:\n",
    "                x = int(hand_landmarks.landmark[index].x * width)\n",
    "                y = int(hand_landmarks.landmark[index].y * height)\n",
    "                coordinates_fb.append([x, y])\n",
    "\n",
    "            ##########################\n",
    "            # Pulgar\n",
    "            p1 = np.array(coordinates_thumb[0])\n",
    "            p2 = np.array(coordinates_thumb[1])\n",
    "            p3 = np.array(coordinates_thumb[2])\n",
    "            l1 = np.linalg.norm(p2 - p3)\n",
    "            l2 = np.linalg.norm(p1 - p3)\n",
    "            l3 = np.linalg.norm(p1 - p2)\n",
    "            # Calcular el ángulo\n",
    "            to_angle = (l1**2 + l3**2 - l2**2) / (2 * l1 * l3)\n",
    "            if int(to_angle) == -1:\n",
    "                angle = 180\n",
    "            else:\n",
    "                angle = degrees(acos(to_angle))\n",
    "            thumb_finger = np.array(False)\n",
    "            if angle > 150:\n",
    "                thumb_finger = np.array(True)\n",
    "            \n",
    "            ################################\n",
    "            # Índice, medio, anular y meñique\n",
    "            nx, ny = palm_centroid(coordinates_palm)\n",
    "            cv2.circle(frame, (nx, ny), 3, (0, 255, 0), 2)\n",
    "            coordinates_centroid = np.array([nx, ny])\n",
    "            coordinates_ft = np.array(coordinates_ft)\n",
    "            coordinates_fb = np.array(coordinates_fb)\n",
    "            # Distancias\n",
    "            d_centrid_ft = np.linalg.norm(coordinates_centroid - coordinates_ft, axis=1)\n",
    "            d_centrid_fb = np.linalg.norm(coordinates_centroid - coordinates_fb, axis=1)\n",
    "            dif = d_centrid_ft - d_centrid_fb\n",
    "            fingers = dif > 0\n",
    "            fingers = np.append(thumb_finger, fingers)\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "    return fingers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation:\n",
    "https://github.com/google/mediapipe/blob/master/docs/solutions/pose.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
